we know how those peripheral effects feedback and influence
behavior. When we confront a moral choice, the dlPFC doesn’t
adjudicate in contemplative silence. The waters roil below.
The pattern of activation in these regions predicts moral
decisions better than does the dlPFC’s profile. And this matches
behavior—people punish to the extent that they feel angered by
someone acting unethically.8
People tend toward instantaneous moral reactions; moreover,
when subjects shift from judging nonmoral elements of acts to
moral ones, they make assessments faster, the antithesis of moral
decision making being about grinding cognition. Most strikingly,
when facing a moral quandary, activation in the amygdala,
vmPFC, and insula typically precedes dlPFC activation.9
Damage to these intuitionist brain regions makes moral
judgments more pragmatic, even coldhearted. Recall from
chapter 10 how people with damage to the (emotional) vmPFC
readily advocate sacrificing one relative to save five strangers,
something control subjects never do.
Most telling is when we have strong moral opinions but can’t tell
why, something Haidt calls “moral dumbfounding”—followed
by clunky post-hoc rationalizing.10 Moreover, such moral
decisions can differ markedly in different affective or visceral
circumstances, generating very different rationalizations. Recall
from the last chapter how people become more conservative in
their social judgments when they’re smelling a foul odor or
sitting at a dirty desk. And then there’s that doozy of a finding—
knowing a judge’s opinions about Plato, Nietzsche, Rawls, and
any other philosopher whose name I just looked up gives you
less predictive power about her judicial decisions than knowing
if she’s hungry.
The social intuitionist roots of morality are bolstered further by
evidence of moral judgment in two classes of individuals with limited
482